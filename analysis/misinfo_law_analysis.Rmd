---
title: "misinfo_law_analysis"
output: pdf_document
date: "2025-03-10"
---


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
library(olsrr)

library(car)
library(tidyverse)

library(ggplot2)
library(reshape2)
library(vdemdata)
library(countrycode)
library(GGally)
library(broom)

library(MASS)

library(lfe)

```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
file_list <- list.files(path = "~/governemnt_takedown/data/", pattern ="PRPL-Facebook-Government-Report-20?", full.names = TRUE) 
data_list <- list()

```




```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#clean dfs so they can be combined into one file


data_list <- list()
for (file in file_list) {
  # Read the current CSV file into a dataframe
  #print(file)
  df <- read.csv(file)
  
  # Extract the file name from the file path
  file_name <- basename(file)
  
  # Extract the year and half information from the file name
  # Assuming the format is like "PRPL-Facebook-Government-Report-YYYY_HX"
  # Where YYYY is the year and HX is the half of the year (H1 or H2)
  year_half <- gsub(".*-(\\d{4})_(H[12]).csv$", "\\1_\\2", file_name)
  
  # Split the extracted information into year and half
  year <- sub("_(H[12])$", "", year_half)
  half <- sub("^\\d{4}_(H[12])$", "\\1", year_half)
  
  # Determine the date based on the half of the year
  if (half == "H1") {
    date <- paste0("6/30/", year)
  } else if (half == "H2") {
    date <- paste0("12/31/", year)
  } else {
    date <- NA  # Handle unexpected cases
  }
  
  # df$Total.Requests.Percentage <- df$Total.Requests.Percentage|> 
  # str_replace_all("%|,", "")
  # 
  # 
  # df$Total.Requests <- sub(" -.*", "", df$Total.Requests)
  # df$Total.Requests <- df$Total.Requests |>
  #   str_replace_all("%|,", "")
  # 
  # df$Total.Requests.Accounts <- sub(" -.*", "", df$Total.Requests.Accounts)
  # df$Total.Requests.Accounts <- df$Total.Requests.Accounts |>
  #   str_replace_all("%|,", "")
  #   #unique(df$Total.Requests.Accounts)
  # 
  
  for (col in names(df)) {
    #print(col)
    if (col != "Country") {
      # Try to convert columns to numeric if they are not character columns
      # This will also handle integer and double columns consistently
      df[[col]] <- sub(" -.*", "", df[[col]])
      df[[col]] <- df[[col]] |>
        str_replace_all("%|,", "")
      
      df[[col]] <- as.numeric(df[[col]])
    }
  }
  
  # Add a new column with the date information
  df$Date <- date
  
  # Append the dataframe to the list
  data_list[[length(data_list) + 1]] <- df
}

```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

initial_df <- bind_rows(data_list)
combined_df <- initial_df
head(combined_df)
head(data_list[[3]])
sum(is.na(initial_df$Total.Requests.Percentage))

names(initial_df)
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#Remove columns with no data


combined_df <- combined_df |> dplyr::select(where(~ any(!is.na(.))))
combined_df |> filter(!is.na(Total.Requests.Percentage)) -> combined_df
combined_df$Platform <- "Facebook"
#add platform column, 
combined_df$Platform <- "Facebook"
head(combined_df)

#combined_df <- subset(combined_df, select = -platform)
#head(combined_df)
#reorder columns
combined_df <- combined_df %>% dplyr::select(Platform, Date, everything())

```





```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
combined_df$Content.Restrictions <- coalesce(combined_df$Content.Restrictions, combined_df$Content.Restricted)


combined_df <- combined_df |> dplyr::select(-Content.Restricted)
```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
combined_df <- combined_df %>% dplyr::select(Platform, Date,Country, Content.Restrictions, everything())
names(combined_df)

#does content restrictions change by country
#does total request change by country


#series of chi square tests, one for each time period?

```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#install.packages("vdemdata")

#install.packages("devtools")
#devtools::install_github("vdeminstitute/vdemdata")



data("vdem")

#head(vdem)
#names(vdem)
#v2x_libdem

 
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#install.packages("countrycode")


# Ensure `date` column is of Date type (if not already)
combined_df$Date <- as.Date(combined_df$Date, format="%m/%d/%Y")
# Extract year from the `date` column in combined_df
combined_df <- combined_df %>%
  mutate(year = format(Date, "%Y"))  # Add a `year` column
# Convert `year` in both dataframes to numeric to avoid mismatches
combined_df$year <- as.numeric(combined_df$year)
vdem$year <- as.numeric(vdem$year)
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

# Merge the dataframes using `left_join` based on country and year
#combined_df <- combined_df %>%
#names(vdem)
#names(combined_df)

vdem |> filter(str_detect(country_name, regex("^Cz")))


#vdem |> mutate(country_name = str_replace("Czechia", ""))
#unique(trouble_names_df$Country)

#trouble_names_df

# 
#only countries with libdem are somaliland (SML) and Kosovo (XKX)
# vdem |> filter(country_name %in% trouble_names_df$Country) |>
#   select(c(country_name, country_text_id, v2x_libdem)) |>
#   unique()



combined_df$country_code <- countrycode(combined_df$Country, "country.name", "iso3c")


# combined_df 
# names(vdem)
# vdem |> select(c(country_name, v2x_libdem)) |>
#   filter(str_detect(country_name, regex("^B")))




#fix kosovo, somaliland, save dropped countries
combined_df |> 
  mutate(country_code = case_when(
    Country == "Kosovo" ~ "XKX",
    Country == "Somaliland" ~ "SML",
    TRUE ~ country_code
  )) |> #left_join(vdem |> dplyr::select(country_name, country_text_id, year, v2x_libdem), 
#            by = c("country_code" = "country_text_id", "year" = "year")) |>
  dplyr::select(Country, country_name, country_code, year, everything()) -> combined_df

#combined_df
#combined_df |> filter(is.na(v2x_libdem)) -> trouble_names_df

#unique(trouble_names_df$Country) -> dropped_countries



#edit the working df to not include countries without a v2x_libdem score 

#combined_df |> filter(!is.na(v2x_libdem)) -> combined_df


```

#import misinfo data, add country codes

```{r}
#examples
getwd()
misinfo_df <- read_excel("../data/Misinformation_Law_Dataset.xlsx", sheet = "Laws by Country and Year", na = c("", "NA", ".."))


misinfo_df$country_code <- countrycode(misinfo_df$Country, "country.name", "iso3c")



```

```{r}

misinfo_df |> dplyr::mutate("has_law" = Law...2) |>
  mutate(year_enacted = `Year enacted`) |>
  dplyr::select(country_code, has_law, Repealed, year_enacted)|>
  # Group by country code
  group_by(country_code) %>%
  # Arrange by Year enacted within each group (NA values last)
  arrange(country_code, year_enacted) %>%
  # Take the first row of each group (which will be the lowest non-NA year)
  # If all values are NA, it will just take the first row
  slice(1) %>%
  # Remove the grouping
  ungroup() -> misinfo_laws_df

```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#Load population, %population data
pop_df <- read_csv("../data/API_IT.NET.USER.ZS_DS2_en_csv_v2_3409961.csv", col_names = TRUE, skip=4)
#head(pop_df)
###help(read_csv)

pop_df <- pop_df |> dplyr::select(c(`Country Name`, `Country Code`) | starts_with('201') | starts_with('202')) |>
  dplyr::select(!c("2010", "2011", "2012"))
#names(pop_df)
###help(select)
```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#pivot longer to group cols 
pop_df_fixed <- pop_df |> pivot_longer(cols = starts_with('20'), names_to = "year", values_to = "percent_pop_on_internet")
#names(pop_df_fixed)

###help(pivot_longer)
unique(pop_df_fixed$`Country Code`)
pop_df_fixed |> filter(str_detect(`Country Name`, regex("^S")))
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
pop_df_fixed$year <- as.numeric(pop_df_fixed$year)
head(pop_df_fixed)
# 
# pop_df_fixed|> filter(`Country Name` %in% trouble_countries_df$country_name) |>
#   filter(!is.na(percent_pop_on_internet))
# 



```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
# Not sure if any of this needs to be ran, see next code chunk for solution
# combined_df |> left_join(pop_df_fixed, by = c("country_code" = "Country Code", "year" = "year")) -> joined_combined_df
# 
# 
# joined_combined_df$country_code <- as.factor(joined_combined_df$country_code)
# 
# joined_combined_df|>
#   group_by(country_code)|>
#   mutate(percent_pop_on_internet = ifelse(is.na(percent_pop_on_internet), mean(percent_pop_on_internet[!is.na(percent_pop_on_internet)], na.rm = TRUE), percent_pop_on_internet)) |>
#   ungroup() |>
#   select(c(Country,country_code, year, percent_pop_on_internet)) |>
#   filter(country_code == "XKX")
# 
# ##help(group_by)
# 
# 
# combined_df |> left_join(pop_df_fixed, by = c("country_code" = "Country Code", "year" = "year"))  |> filter(is.na(percent_pop_on_internet))|>
#   select(c(Country, country_code, year, percent_pop_on_internet))
# 
# combined_df |> left_join(pop_df_fixed, by = c("country_code" = "Country Code", "year" = "year"))  |> group_by(country_code)
# 
# head(combined_df)
```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#set NAs to country median, 

combined_df |> left_join(pop_df_fixed, by = c("country_code" = "Country Code", "year" = "year")) -> joined_combined_df


joined_combined_df$country_code <- as.factor(joined_combined_df$country_code)




joined_combined_df |>
  dplyr::group_by(country_code) %>%
  dplyr::mutate(percent_pop_on_internet = ifelse(
    is.na(percent_pop_on_internet), 
    median(percent_pop_on_internet[!is.na(percent_pop_on_internet)], na.rm = TRUE), 
    percent_pop_on_internet)) %>%
  ungroup() |>
  filter(!is.na(percent_pop_on_internet)) -> combined_df

```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#checking NAs, 0 is good
combined_df |> filter(is.na(percent_pop_on_internet))
sum(is.na(combined_df$percent_pop_on_internet))
```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#Load population data

flat_pop_df <- read_csv("../data/API_SP.POP.TOTL_DS2_en_csv_v2_3401680.csv", col_names = TRUE, skip=4)
head(flat_pop_df)


flat_pop_df <- flat_pop_df |> 
  dplyr::select(c(`Country Code`) | starts_with('201') | starts_with('202')) |>
  dplyr::select(!c("2010", "2011", "2012"))
names(flat_pop_df)


```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#pivot longer to group cols 
flat_pop_df_fixed <- flat_pop_df |> pivot_longer(cols = starts_with('20'), names_to = "year", values_to = "population")
names(flat_pop_df_fixed)

###help(pivot_longer)
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
flat_pop_df_fixed$year <- as.numeric(flat_pop_df_fixed$year)

head(combined_df)
#combined_df |> select(-c(`Country Code`, population)) -> combined_df
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
combined_df |> left_join(flat_pop_df_fixed, by = c("country_code" = "Country Code", "year" = "year")) -> combined_df

combined_df
#joined_combined_df |> select(c(Country,country_code, population, year) )

#joined_combined_df$country_code <- as.factor(joined_combined_df$country_code)


```





```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#rewriting to add in country offices
office_df <- read_csv("../data/Local-Offices-1.csv", col_names = TRUE)
head(office_df)

##help(rename)
office_df <- office_df |> 
  dplyr::mutate("has_facebook_office" = `Facebook Office (1-0)`,
         "has_twitter_office" = `Twitter Office (1-0)`,
         "has_google_office" = `Google Office (1-0)` ) |>
  dplyr::select(-c(`Facebook Office (1-0)`,`Twitter Office (1-0)`,`Google Office (1-0)`))
head(office_df)


office_df$country_code <- countrycode(office_df$Country, "country.name", "iso3c")
office_df |>
  mutate(country_code = case_when(
    str_detect(Country, regex("^Cote")) ~ "CIV",
    Country == "Kosovo" ~ "XKX",
    TRUE ~ country_code)) |> filter(!is.na(country_code)) ->
  office_df

```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

office_df


combined_df <- combined_df |>
  left_join(office_df, by = c("country_code" = "country_code"))

combined_df |> names()

combined_df |> mutate(Country = Country.x) |> dplyr::select(-c(Country.y, Country.x)) |>
  dplyr::select(Country, everything()) -> combined_df

#combined_df |> select(-c(has_facebook_office, has_google_office, has_twitter_office)) ->
#  combined_df



```





```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#load in country GDP data, should be similar to world bank data
#"./API_NY.GDP.MKTP.CD_DS2_en_csv_v2_31795.csv"
gdp_df <- read_csv("../data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_31795.csv", col_names = TRUE, skip=4)
head(gdp_df)


gdp_df <- gdp_df |> 
  dplyr::select(c(`Country Name`, `Country Code`)| starts_with('201') | starts_with('202')) |>
  dplyr::select(!c("2010", "2011", "2012"))
names(gdp_df)

```





```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#pivot longer to group cols 
gdp_df_fixed <- gdp_df |> pivot_longer(cols = starts_with('20'), names_to = "year", values_to = "GDP")
names(gdp_df_fixed)
gdp_df_fixed |> dplyr::select(-`Country Name`) -> gdp_df_fixed


gdp_df_fixed$year <- as.numeric(gdp_df_fixed$year)

gdp_df_fixed

###help(pivot_longer)
```




```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#head(combined_df)



combined_df |> left_join(gdp_df_fixed, by = c("country_code" = "Country Code", "year" = "year")) -> joined_combined_df
joined_combined_df |> dplyr::select(c(Country,country_code, population, year) )

joined_combined_df$country_code <- as.factor(joined_combined_df$country_code)

```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
joined_combined_df$year <- as.numeric(joined_combined_df$year)
joined_combined_df
head(combined_df)
joined_combined_df -> combined_df
```










```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#add in v2smgovsmmon, v2smgovfilcap, v2smarrest

civic_df <- read_csv("../data/DSP_CY_v6.csv", col_names = TRUE)
head(civic_df)


civic_df <- civic_df |> 
  dplyr::select(c("country_name", "country_text_id", "year","v2smgovsmmon", "v2smgovfilcap", "v2smarrest"))
names(civic_df)

```




```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
civic_df$year <- as.numeric(civic_df$year)

combined_df |> left_join(civic_df, by = c("country_code" = "country_text_id", "year" = "year")) -> combined_df


head(combined_df)
```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#load in political regime type
regime_df <- read_csv("../data/political-regime.csv", col_names = TRUE)

#regime_df

regime_df <- regime_df |>
  dplyr::select(c("Entity","Code","Year", "Political regime"))
names(regime_df)

regime_df <- regime_df |>
  filter(Year >= 2013)

regime_df
regime_df$year <- as.numeric(regime_df$Year)
regime_df
#regime_df <- regime_df |> select(-Year)

head(regime_df)

names(combined_df)
names(regime_df)



#regime_df |> mutate(Code = str_trim(Code)) -> regime_df


#filter(Entity %in% c("Egypt", "Kosovo", "Palestine"))

#combined_df |> filter(Country %in% c("Egypt", "Kosovo", "Palestine"))

combined_df |>
  left_join(regime_df, by = c("country_code" = "Code", "year" = "year")) |> mutate(`Political regime` = case_when(
    Country == "Kosovo" ~ 2,
    Country == "Egypt" ~ 1, 
    TRUE~ `Political regime`
  )) |> dplyr::select(-c(country_name.x, Entity)) -> combined_df

#convert dates to datetype
typeof(combined_df$Date)

combined_df$Date <- ymd(combined_df$Date)
#no_regime_countries

#unique(no_regime_countries$Country)



combined_df
```




```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#Use later for assessing associations between variables
combined_df |> dplyr::select(-c(`Country Name`, country_name.y )) -> combined_df



#install.packages("GGally")

#ggpairs(df, columns=c(..,..,..,..))
#ggpairs(sat, columns = 2:8)
```




```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#must update path to match when swapping pcs

#add total content restrictions by country
file_list <- list.files(path = "~/governemnt_takedown/data", pattern ="Content_Restrictions_20?", full.names = TRUE) 
data_list <- list()

file_list
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
data_list <- list()
for (file in file_list) {
  # Read the current CSV file into a dataframe
  #print(file)
  df <- read.csv(file)
  
  # Extract the file name from the file path
  file_name <- basename(file)
  
  # Extract the year and half information from the file name
  # Assuming the format is like "PRPL-Facebook-Government-Report-YYYY_HX"
  # Where YYYY is the year and HX is the half of the year (H1 or H2)
  year_half <- gsub(".*_(\\d{4})_(H[12]).csv$", "\\1_\\2", file_name)
  
  # Split the extracted information into year and half
  year <- sub("_(H[12])$", "", year_half)
  half <- sub("^\\d{4}_(H[12])$", "\\1", year_half)
  
  # Determine the date based on the half of the year
  if (half == "H1") {
    date <- paste0("6/30/", year)
  } else if (half == "H2") {
    date <- paste0("12/31/", year)
  } else {
    date <- NA  # Handle unexpected cases
  }
  
  
  # df$Total.Requests.Percentage <- df$Total.Requests.Percentage|> 
  # str_replace_all("%|,", "")
  # 
  # 
  # df$Total.Requests <- sub(" -.*", "", df$Total.Requests)
  # df$Total.Requests <- df$Total.Requests |>
  #   str_replace_all("%|,", "")
  # 
  # df$Total.Requests.Accounts <- sub(" -.*", "", df$Total.Requests.Accounts)
  # df$Total.Requests.Accounts <- df$Total.Requests.Accounts |>
  #   str_replace_all("%|,", "")
  #   #unique(df$Total.Requests.Accounts)
  # 
  
  for (col in names(df)) {
    #print(col)
    if (col != "Country") {
      # Try to convert columns to numeric if they are not character columns
      # This will also handle integer and double columns consistently
      df[[col]] <- sub(" -.*", "", df[[col]])
      df[[col]] <- df[[col]] |>
        str_replace_all("%|,", "")
      
      df[[col]] <- as.numeric(df[[col]])
    }
  }
  
  # Add a new column with the date information
  df$Date <- date
  
  # Append the dataframe to the list
  data_list[[length(data_list) + 1]] <- df
}

```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

content_restrictions_df <- bind_rows(data_list)
head(content_restrictions_df)
unique(content_restrictions_df$count)
sum(!is.na(content_restrictions_df$total))
sum(is.na(content_restrictions_df$count))

length(content_restrictions_df$total)
length(content_restrictions_df$count)

```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
# fix NAs from coercion above by combining totals and count columns, 
coalesce(content_restrictions_df$count, content_restrictions_df$total) -> content_restrictions_df$total
content_restrictions_df

content_restrictions_df |> dplyr::select(-count) |> dplyr::select(Country, total, Date, everything()) 

#convert to date
content_restrictions_df$Date <- mdy(content_restrictions_df$Date)
#add year as a separate column
content_restrictions_df$year <- year(content_restrictions_df$Date)
```




```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

# then removing subcategory columns, then coalescing by date + add year column.\
head(content_restrictions_df)
content_restrictions_df |> dplyr::select(-c(ISO.Code, starts_with("Facebook"), starts_with("Instagram"))) -> content_restrictions_df


content_restrictions_df
```




```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#add ISO country codes to countries for join, remove count column
content_restrictions_df$country_code <- countrycode(content_restrictions_df$Country, "country.name", "iso3c")
head(content_restrictions_df)

content_restrictions_df |> dplyr::select(c(-count, -Country)) -> content_restrictions_df
content_restrictions_df |> dplyr::mutate("total_content_takedowns" = total) |> dplyr::select(c(-total)) -> content_restrictions_df

names(content_restrictions_df)
unique(content_restrictions_df$Date)
unique(combined_df$Date)
```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#TODO combine content_restrictions_df and main df
names(combined_df)
combined_df |> left_join(content_restrictions_df, by=c('country_code' = 'country_code', 'Date' = 'Date','year' = 'year')) -> test_df
content_restrictions_df

test_df

names(test_df)
sum(!is.na(test_df$total_content_takedowns))
sum(!is.na(content_restrictions_df$total_content_takedowns))
sum(!is.na(content_restrictions_df$total_content_takedowns))-sum(!is.na(test_df$total_content_takedowns))

sum(is.na(test_df$total_content_takedowns)) 


test_df |> filter(is.na(total_content_takedowns))|> dplyr::select(Country, country_code, Date, total_content_takedowns, everything()) -> problems_df

problems_df |> arrange(Date, year, country_code)
content_restrictions_df |> arrange(Date, year,country_code)
unique(problems_df) 

#TODO test_df is joined, contains all of combined df and the total number of content takedowns
#for analysis on content takedowns, drop rows where total_content_takedowns = na and run on that df separately
#should be about 2k rows left


```










```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#begin models
#start with just libdem and total requests

#only use date for models, NOT year, year has multiple entries for the same year and country due to split
names(combined_df)
#Should contain Country, country_code, year, platform, Date, libdem, social media gov metrics, population, percent pop on internet, regime type, existence of a facebook office, GDP

model_df <- combined_df


#names(model_df)

model_df$country_code <- as.factor(model_df$country_code)

model_df$Date <- as.Date(model_df$Date)
model_df$date_numeric <- as.numeric(model_df$Date)
model_df$year <- as.numeric(model_df$year)
  
model <- lm(Total.Requests ~ v2x_libdem + date_numeric, data = model_df)
date_model <- lm(Total.Requests ~ v2x_libdem + Date, data = model_df)
summary(model)
summary(date_model)
#sum(is.na(model_df$Total.Requests.Percentage))

```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
restrictions_model_df <- test_df



restrictions_model_df$country_code <- as.factor(restrictions_model_df$country_code)
restrictions_model_df$year <- as.numeric(restrictions_model_df$year)
  
restrictions_model <- lm(Total.Requests ~ v2x_libdem + year, data = model_df)
summary(restrictions_model)

```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#removing NAs/ irrelevant columns

sapply(model_df, function(x) sum(is.na(x)))
model_df |> dplyr::select(c(-starts_with('Court'), -starts_with('Legal'), -starts_with('Emergency'), -starts_with('Subpoena'), -starts_with('Pen'), -starts_with('Title'), -starts_with('Search'), -starts_with('ER'), -starts_with('Preservation'))) -> model_df_cut_cols

model_df_cut_cols
model_df_cut_cols |> filter(!is.na(Total.Requests.Percentage)) ->model_df_cut_cols
sapply(model_df_cut_cols, function(x) sum(is.na(x)))



model_df_cut_cols |> filter(is.na(v2x_libdem))

```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
sapply(restrictions_model_df, function(x) sum(is.na(x)))
restrictions_model_df |> dplyr::select(c(-starts_with('Court'), -starts_with('Legal'), -starts_with('Emergency'), -starts_with('Subpoena'), -starts_with('Pen'), -starts_with('Title'), -starts_with('Search'), -starts_with('ER'), -starts_with('Preservation'))) -> restrictions_model_df_cut_cols

model_df_cut_cols
#model_df_cut_cols |> filter(!is.na(Total.Requests.Percentage)) ->model_df_cut_cols
sapply(model_df_cut_cols, function(x) sum(is.na(x)))



```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#fixes column names,
#names(model_df)
names(restrictions_model_df_cut_cols)
model_df_cut_cols |> mutate(political_regime = `Political regime`) -> model_df_cut_cols

restrictions_model_df_cut_cols |> mutate(political_regime = `Political regime`) -> restrictions_model_df_cut_cols



#Remove NA GDP and political regime values only
model_df_cut_cols |> filter(!is.na(GDP)) |> filter(!is.na(political_regime))-> model_df_cut_cols

restrictions_model_df_cut_cols |> filter(!is.na(GDP))|> filter(!is.na(political_regime))-> restrictions_model_df_cut_cols


names(restrictions_model_df_cut_cols)
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#include log versions of population and GDP, as well as pop*percentpop on internet
min(model_df_cut_cols$percent_pop_on_internet)

model_df_cut_cols |> mutate(log_pop = log(population), log_gdp = log(GDP), pop_on_internet = population*percent_pop_on_internet*.01, log_pop_on_internet = log(pop_on_internet)) -> model_df_cut_cols


```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#same as above but for restrictions_model df
restrictions_model_df_cut_cols |> mutate(log_pop = log(population), log_gdp = log(GDP), pop_on_internet = population*percent_pop_on_internet*.01, log_pop_on_internet = log(pop_on_internet)) -> restrictions_model_df_cut_cols
names(restrictions_model_df_cut_cols)
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
restrictions_model_df_cut_cols$political_regime_factor <- as.factor(restrictions_model_df_cut_cols$political_regime) 
model_df_cut_cols$political_regime_factor <- as.factor(model_df_cut_cols$political_regime) 

```





```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#trains model on all relevant variables included

#NOTE: 

#
#ols
#logit
#0 inflated binomial regression


#Total requests number
total_requests_all_vars <- lm(Total.Requests ~ v2x_libdem + has_facebook_office +GDP + v2smgovsmmon+v2smgovfilcap+ v2smarrest+ political_regime + Date + population + percent_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_all_vars)

#include logged population and gdp
total_requests_logged_vars <- lm(Total.Requests ~ v2x_libdem + has_facebook_office + log_gdp + v2smgovsmmon+v2smgovfilcap+ v2smarrest+ political_regime + Date + log_pop + percent_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_logged_vars)



#remove population/pop percent on internet for logged internet population

total_requests_logged_pop_internet <- lm(Total.Requests ~ v2x_libdem + has_facebook_office + log_gdp + v2smgovsmmon+v2smgovfilcap+ v2smarrest+ political_regime + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_logged_pop_internet)


```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
# 
# #  Multicollinearity testing
# 
# # VIF scores of 5-10 or higher indicate high multicollinearity, 
# # cor function allows you to see correlation between individual variables. closer to 1 or to -1 indicate high correlation
# 
# # vdem scores show high multicollinearity, should run separate models for each of the 
# 
# 
# 
# sapply(model_df_cut_cols, function(x) sum(is.na(x)))
# #5-10 or higher = multicollinearity issues
# vif(total_requests_all_vars)
# vif(total_requests_logged_vars)
# 
# 
# numeric_vars <- model_df_cut_cols[, c("v2x_libdem", "v2smgovsmmon", "v2smarrest", "political_regime","GDP", "population", "v2smgovfilcap")]
# cor(numeric_vars)
# 
# ols_eigen_cindex(total_requests_all_vars)


```





```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#loading in datafinder set
#fhn_fotnsc, fhn_fotnvur, fi_index (maybe), 


datafinder_df <-  read_csv("../data/qog_oecd_ts_jan24.csv")

head(datafinder_df)
names(datafinder_df)

```


#fhn_fotnsc, fhn_fotnvur, fi_index (these don't seem to be in the actual spreadsheet despite being shown in the codebase)

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
datafinder_df |> dplyr::select(year, ccodealp, fh_cl, fh_fog)|>
  dplyr::filter(year > 2013) -> datafinder_df_fh_data#add in additional variables of interest


```
```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
datafinder_df_fh_data |> dplyr::mutate(code = ccodealp) |> dplyr::select(-ccodealp) |>
  filter(!is.na(fh_cl)) |> filter(!is.na(fh_fog)) -> datafinder_df_fh_data
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
names(model_df_cut_cols)
datafinder_df_fh_data |> left_join(model_df_cut_cols, by = c("code" = "country_code", "year" = "year")) 
```





```{r, cache=TRUE,cache.lazy = FALSE, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#pull in ACLED Data
library(aRxiv)
library(keyring)
library(httr2)

key_get("ACLED_Key")
```


```{r, cache=TRUE,cache.lazy = FALSE, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
unique(model_df_cut_cols$year)
search_req_acled <- request("https://api.acleddata.com/acled/read/")

search_req_acled |>
  #req_url_query(q="artificial intelligence") |>
  req_url_query(key = keyring::key_get("ACLED_Key")) |>
  req_url_query(email="sbradshaw@american.edu")|>
  req_url_query(year="2015|2023")|>
  req_url_query(year_where="BETWEEN")|>
  req_url_query(limit="6000000")|>
  
  #New line added to target ethiopia
  #req_url_query(country="Ethiopia")|>
  #req_dry_run()
  req_perform() -> search_resp_acled

```



```{r, cache=TRUE,cache.lazy = FALSE, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#resp_status(search_resp_acled)
#resp_body_json(search_resp_acled) |> glimpse()

resp_body_json(search_resp_acled)$data -> acled_list

tibble(acled_list) -> acled_df

#head(acled_df)
#acled_df[[1]]
#names(acled_df[[1]])

acled_df |>
  hoist(.col = acled_list,
        year = "year",
        event_type = "event_type",
        disorder_type = "disorder_type",    # havent tested with one yet
        country = "country") -> acled_df_hoist

#head(acled_df_hoist)
#head(acled_list)


acled_df_hoist %>%
  group_by(year, country, event_type) %>%
  summarize(count = n(), .groups = 'drop') %>%
  pivot_wider(names_from = event_type, values_from = count, values_fill = 0) |>
  mutate(explosions_remote_violence = `Explosions/Remote violence`, 
         strategic_developments = `Strategic developments`,
         violence_against_civilians = `Violence against civilians`) |>
  dplyr::select(-c(`Explosions/Remote violence`, `Violence against civilians`, `Strategic developments`)) |>
  mutate(total_events = Battles + Protests+Riots+explosions_remote_violence + strategic_developments + violence_against_civilians) -> acled_df

#acled_df



```

```{r, cache=TRUE,cache.lazy = FALSE, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
acled_df$country_code <- countrycode(acled_df$country, "country.name", "iso3c")


acled_df |> dplyr::select(-country) |> dplyr::select(country_code, year, everything()) -> acled_df
```

```{r}
acled_df
```


```{r, cache=TRUE,cache.lazy = FALSE, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#pull country name, year, event_type, disorder_type
names(model_df_cut_cols)

acled_df$year <- as.numeric(acled_df$year)
acled_df |> left_join(model_df_cut_cols, by= c("country_code" = "country_code", "year"="year")) |>
  filter(!is.na(Total.Requests)) |> filter(!is.na(Total.Requests.Percentage))-> facebook_acled_df
  #filter(!is.na(political_regime_factor))



```





















```{r, cache=TRUE,cache.lazy = FALSE, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#original fb modeling starts here
#EVERYTHING model
total_requests_logged_pop_internet <- lm(Total.Requests ~ v2x_libdem + has_facebook_office + log_gdp + v2smgovsmmon+v2smgovfilcap+ v2smarrest+ political_regime + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_logged_pop_internet)
```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
# EVERYTHING model with political regime as factor

total_requests_logged_pop_internet_factor <- lm(Total.Requests ~ v2x_libdem + has_facebook_office + log_gdp + v2smgovsmmon+v2smgovfilcap+ v2smarrest+ political_regime_factor + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_logged_pop_internet_factor)

```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

total_requests_logged_pop_internet_libdem <- lm(Total.Requests ~ v2x_libdem + has_facebook_office + log_gdp + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_logged_pop_internet_libdem)

total_requests_logged_pop_internet_smgosvsmmon <- lm(Total.Requests ~  has_facebook_office + log_gdp + v2smgovsmmon + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_logged_pop_internet_smgosvsmmon)

total_requests_logged_pop_internet_smarrest <- lm(Total.Requests ~ has_facebook_office + log_gdp + v2smarrest + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_logged_pop_internet_smarrest)

total_requests_logged_pop_internet_political_regime <- lm(Total.Requests ~ has_facebook_office + log_gdp + political_regime + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_logged_pop_internet_political_regime)

total_requests_logged_pop_internet_political_regime_factor <- lm(Total.Requests ~ has_facebook_office + log_gdp + political_regime_factor + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_logged_pop_internet_political_regime)


```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#original model, percent_requests
#Percentage Requests Start Here
total_requests_percent_logged_pop_internet <- lm(Total.Requests.Percentage ~ v2x_libdem + has_facebook_office + log_gdp + v2smgovsmmon+v2smgovfilcap+ v2smarrest+ political_regime + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_percent_logged_pop_internet)


total_requests_percent_logged_pop_internet_factor <- lm(Total.Requests.Percentage ~ v2x_libdem + has_facebook_office + log_gdp + v2smgovsmmon+v2smgovfilcap+ v2smarrest+ political_regime_factor + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_percent_logged_pop_internet_factor)


total_requests_percent_logged_pop_internet_libdem <- lm(Total.Requests.Percentage ~ v2x_libdem + has_facebook_office + log_gdp + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_percent_logged_pop_internet_libdem)

total_requests_percent_logged_pop_internet_smgosvsmmon <- lm(Total.Requests.Percentage ~  has_facebook_office + log_gdp + v2smgovsmmon + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_percent_logged_pop_internet_smgosvsmmon)

total_requests_percent_logged_pop_internet_smarrest <- lm(Total.Requests.Percentage ~ has_facebook_office + log_gdp + v2smarrest + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_percent_logged_pop_internet_smarrest)

total_requests_percent_logged_pop_internet_political_regime <- lm(Total.Requests.Percentage ~ has_facebook_office + log_gdp + political_regime + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_percent_logged_pop_internet_political_regime)


total_requests_percent_logged_pop_internet_political_regime_factor <- lm(Total.Requests.Percentage ~ has_facebook_office + log_gdp + political_regime_factor + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_percent_logged_pop_internet_political_regime_factor)


#Base Model


total_requests_percent_logged_pop_internet_base <- lm(Total.Requests.Percentage ~ log_gdp + Date + log_pop_on_internet, data = model_df_cut_cols)
summary(total_requests_percent_logged_pop_internet_base)

```






```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#total content takedowns start here
#original model, total content takedowns
content_takedowns_logged_pop_internet <- lm(total_content_takedowns ~ v2x_libdem + has_facebook_office + log_gdp + v2smgovsmmon+v2smgovfilcap+ v2smarrest+ political_regime + Date + log_pop_on_internet, data = restrictions_model_df_cut_cols)
summary(content_takedowns_logged_pop_internet)


content_takedowns_logged_pop_internet_factor <- lm(total_content_takedowns ~ v2x_libdem + has_facebook_office + log_gdp + v2smgovsmmon+v2smgovfilcap+ v2smarrest+ political_regime_factor + Date + log_pop_on_internet, data = restrictions_model_df_cut_cols)
summary(content_takedowns_logged_pop_internet_factor)


content_takedowns_logged_pop_internet_libdem <- lm(total_content_takedowns ~ v2x_libdem + has_facebook_office + log_gdp + Date + log_pop_on_internet, data = restrictions_model_df_cut_cols)
summary(content_takedowns_logged_pop_internet_libdem)

content_takedowns_logged_pop_internet_smgosvsmmon <- lm(total_content_takedowns ~  has_facebook_office + log_gdp + v2smgovsmmon + Date + log_pop_on_internet, data = restrictions_model_df_cut_cols)
summary(content_takedowns_logged_pop_internet_smgosvsmmon)

content_takedowns_logged_pop_internet_smarrest <- lm(total_content_takedowns ~ has_facebook_office + log_gdp + v2smarrest + Date + log_pop_on_internet, data = restrictions_model_df_cut_cols)
summary(content_takedowns_logged_pop_internet_smarrest)

content_takedowns_logged_pop_internet_political_regime <- lm(total_content_takedowns ~ has_facebook_office + log_gdp + political_regime_factor + Date + log_pop_on_internet, data = restrictions_model_df_cut_cols)
summary(content_takedowns_logged_pop_internet_political_regime)


#Base Model


content_takedowns_logged_pop_internet_base <- lm(total_content_takedowns ~ log_gdp + Date + log_pop_on_internet, data = restrictions_model_df_cut_cols)
summary(content_takedowns_logged_pop_internet_base)

#end results/modeling 1
```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#help(felm)

#has_facebook office breaks felm
#Date and country_code level effects

felm_total_requests_percentage_v2x_libdem <- felm(Total.Requests.Percentage ~  log_gdp + log_pop_on_internet + v2x_libdem | Date + country_code, data = model_df_cut_cols)
summary(felm_total_requests_percentage_v2x_libdem)


felm_total_requests_percentage_v2smgovsmmon <- felm(Total.Requests.Percentage ~  log_gdp + log_pop_on_internet + v2smgovsmmon | Date + country_code, data = model_df_cut_cols)
summary(felm_total_requests_percentage_v2smgovsmmon)


felm_total_requests_percentage_v2smgovfilcap <- felm(Total.Requests.Percentage ~  log_gdp + log_pop_on_internet + v2smgovfilcap | Date + country_code, data = model_df_cut_cols)
summary(felm_total_requests_percentage_v2smgovfilcap)

felm_total_requests_percentage_v2smarrest <- felm(Total.Requests.Percentage ~  log_gdp + log_pop_on_internet + v2smarrest | Date + country_code, data = model_df_cut_cols)
summary(felm_total_requests_percentage_v2smarrest)




#country effects only


felm_total_requests_percentage_country_effects_v2x_libdem <- felm(Total.Requests.Percentage ~   v2x_libdem + Date + log_gdp + log_pop_on_internet + v2x_libdem | country_code, data = model_df_cut_cols)
summary(felm_total_requests_percentage_country_effects_v2x_libdem)


felm_total_requests_percentage_country_effects_v2smgovsmmon <- felm(Total.Requests.Percentage ~   v2smgovsmmon + Date + log_gdp + log_pop_on_internet + v2x_libdem | country_code, data = model_df_cut_cols)
summary(felm_total_requests_percentage_country_effects_v2smgovsmmon)

felm_total_requests_percentage_country_effects_v2smgovfilcap <- felm(Total.Requests.Percentage ~   v2smgovfilcap + Date + log_gdp + log_pop_on_internet + v2x_libdem | country_code, data = model_df_cut_cols)
summary(felm_total_requests_percentage_country_effects_v2smgovfilcap)

felm_total_requests_percentage_country_effects_v2smarrest <- felm(Total.Requests.Percentage ~   v2smarrest + Date + log_gdp + log_pop_on_internet + v2x_libdem | country_code, data = model_df_cut_cols)
summary(felm_total_requests_percentage_country_effects_v2smarrest)



# extra variables to test
#v2x_libdem +v2smgovsmmon+v2smgovfilcap+ v2smarrest
```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

# library(car)

# alias(lm(Total.Requests.Percentage ~ has_facebook_office + log_gdp + political_regime + log_pop_on_internet + Date + country_code, data = model_df_cut_cols))
# vif(lm(Total.Requests.Percentage ~ has_facebook_office + log_gdp + political_regime + log_pop_on_internet + Date + country_code, data = model_df_cut_cols))
```












```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#put in google/twitter data
twitter_df <- read_csv("../data/Twitter_Transparency-Removal_Requests_Jul-Dec-2020.csv", col_names = TRUE, skip = 1)
google_df <- read_csv("../data/google-government-removal-requests.csv", col_names = TRUE)

##help("problems")
#problems(twitter_df)


```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#google steps:

#Change country/region name to country
#Change "Items Requests To Be Removed" to Total.Requests
#change number of requests to requests_approved
#Remove unnecessaty columns (everything but Period Ending, Country/Region, Number of Requests, Items Requested To Be Removed)
google_df |> dplyr::mutate(Country = `Country/Region`, Date = `Period Ending`, Requests_Approved = `Number of Requests`, 
                           Total.Requests = `Items Requested To Be Removed`) |> 
  dplyr::select(c(`Date`, `Country`, `Requests_Approved`, `Total.Requests`)) -> google_df


```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#add in country codes first since text is jank, swap to country codes only
google_df$country_code <- countrycode(google_df$Country, "country.name", "iso3c")

google_df


```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#condense columns of same country and region
unique(google_df$Country)

google_df |>
  dplyr::select(-Country)|>
  dplyr::group_by(country_code, Date) |>
  summarise(across(everything(), sum, na.rm = TRUE), .groups = 'drop') -> google_df

# View the combined dataframe


```



```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#calculate total.requests.percentage as requests approved / total requests
head(combined_df)
##help("round")
names(google_df)
google_df |> mutate(Google.Total.Requests.Percentage = round((Requests_Approved/Total.Requests)*100L )) -> google_df
```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#Add country_codes for join to main df.
names(model_df_cut_cols)
model_df_cut_cols

google_df$year <- year(ymd(google_df$Date))
head(google_df)
```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#fix twitter data to be in the same format
names(twitter_df)

unique(twitter_df$`Time period start`)
twitter_df |> dplyr::select(`Time period start`, Country, `Combined requests`, `Combined compliance rate`) |>
  mutate(Date = `Time period start`, Total.requests = `Combined requests`, 
         Total.Requests.Percentage = `Combined compliance rate`) |> 
  dplyr::select(Date, Country, Total.requests, Total.Requests.Percentage) |>
  dplyr::mutate(across(Total.Requests.Percentage, ~ifelse(.=="NULL", "0", .))) |>
  dplyr::mutate(Date = case_when(
    Date == "7/1/2020" ~ "12/31/2020",
    Date == "1/1/2020" ~ "6/30/2020",
    Date == "7/1/2019" ~ "12/31/2019",
    Date == "1/1/2019" ~ "6/30/2019",
    Date == "7/1/2018" ~ "12/31/2018",
    Date == "1/1/2018" ~ "6/30/2018",
    Date == "7/1/2017" ~ "12/31/2017",
    Date == "1/1/2017" ~ "6/30/2017",
    Date == "7/1/2016" ~ "12/31/2016",
    Date == "1/1/2016" ~ "6/30/2016",
    Date == "7/1/2015" ~ "12/31/2015", 
    Date == "1/1/2015" ~ "6/30/2015",
    Date == "7/1/2014" ~ "12/31/2014",
    Date == "1/1/2014" ~ "6/30/2014",
    Date == "7/1/2013" ~ "12/31/2013",
    Date == "1/1/2013" ~ "6/30/2013",
    Date == "7/1/2012" ~ "12/31/2012",
    Date == "1/1/2012" ~ "6/30/2012"
  )) -> twitter_df
  
twitter_df$country_code <- countrycode(twitter_df$Country, "country.name", "iso3c")
twitter_df |> filter(Country != "Worldwide") |> filter(!is.na(Date)) -> twitter_df

twitter_df |> mutate(Date = mdy(Date)) |> 
  dplyr::select(country_code, Date, Total.requests, Total.Requests.Percentage) -> twitter_df
twitter_df$year <- year(ymd(twitter_df$Date))




```




```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#gpd_df_fixed only contains Country Code, year, GDP
#flat_pop_fixed contains Country Code, year, population
#pop_df_fixed contains Country Code, year, percent_pop_on_internet,

#join with gpd_df_fixed, flat_pop_fixed, pop_df_fixed, vdem, office_df, civic_df(has smarrest, etc)

pop_df_fixed |> dplyr::select(-`Country Name`) -> pop_df_fixed
pop_df_fixed
head(vdem)
pop_df_fixed
google_df
twitter_df


google_df |> left_join(pop_df_fixed, by = c("country_code" = "Country Code", "year" = "year")) -> google_df
twitter_df |> left_join(pop_df_fixed, by = c("country_code" = "Country Code", "year" = "year")) -> twitter_df

```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}


#join with gpd_df_fixed, flat_pop_fixed, vdem, office_df, civic_df(has smarrest, etc)
gdp_df_fixed


google_df |> left_join(gdp_df_fixed, by = c("country_code" = "Country Code", "year" = "year")) -> google_df
twitter_df |> left_join(gdp_df_fixed, by = c("country_code" = "Country Code", "year" = "year")) -> twitter_df


flat_pop_df_fixed

google_df |> left_join(flat_pop_df_fixed, by = c("country_code" = "Country Code", "year" = "year")) -> google_df
twitter_df |> left_join(flat_pop_df_fixed, by = c("country_code" = "Country Code", "year" = "year")) -> twitter_df



google_df |> left_join((office_df |> dplyr::select(c(-Country, -has_facebook_office, -has_twitter_office))), by = c("country_code" = "country_code")) -> google_df
twitter_df |> left_join((office_df |> dplyr::select(c(-Country, -has_facebook_office, -has_google_office))), by = c("country_code" = "country_code")) -> twitter_df

(office_df |> dplyr::select(-Country, -has_facebook_office, -has_twitter_office))
```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#join with civic_df and vdem
civic_df |> 
  dplyr::mutate(country_code = country_text_id)|>
  dplyr::select(-c(country_name, country_text_id)) -> civic_df


civic_df
google_df |> left_join(civic_df, by = c("country_code" = "country_code", "year" = "year")) -> google_df
twitter_df |> left_join(civic_df, by = c("country_code" = "country_code", "year" = "year")) -> twitter_df

google_df
twitter_df

google_df |> left_join(vdem |> dplyr::select(country_text_id, year, v2x_libdem), 
            by = c("country_code" = "country_text_id", "year" = "year")) -> google_df


twitter_df |> left_join(vdem |> dplyr::select(country_text_id, year, v2x_libdem), 
            by = c("country_code" = "country_text_id", "year" = "year"))  -> twitter_df

```




```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#google and twitter data is clean at this point. only steps are to make logs of variables (like what is done for model_df, and to cut na values from the dfs)

#edit code below to target google_df and twitter_df. make factors, and 



#relevant code copied from above, seen after "begin models"
google_df
#test with making factors of country code before saving it, not sure if this breaks modeling
google_df$country_code_factor <- as.factor(google_df$country_code)

google_df$year <- as.numeric(google_df$year)


#code from above to log numerical data
google_df |> mutate(log_pop = log(population), log_gdp = log(GDP), pop_on_internet = population*percent_pop_on_internet*.01, log_pop_on_internet = log(pop_on_internet)) -> google_df



google_df |> mutate(log_pop = log(population), log_gdp = log(GDP), pop_on_internet = population*percent_pop_on_internet*.01, log_pop_on_internet = log(pop_on_internet))

twitter_df$country_code_factor <- as.factor(twitter_df$country_code)

twitter_df$year <- as.numeric(twitter_df$year)

twitter_df |> mutate(log_pop = log(population), log_gdp = log(GDP), pop_on_internet = population*percent_pop_on_internet*.01, log_pop_on_internet = log(pop_on_internet)) -> twitter_df

```

```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#include political regime

regime_df |> dplyr::select(c(Code, year, `Political regime`)) -> regime_df

google_df |> left_join(regime_df, by = c("country_code" = "Code", "year" = "year")) -> google_df

twitter_df |> left_join(regime_df, by = c("country_code" = "Code", "year" = "year")) -> twitter_df


#not sure what this does

# combined_df |>
#   left_join(regime_df, by = c("country_code" = "Code", "year" = "year")) |> mutate(`Political regime` = case_when(
#     Country == "Kosovo" ~ 2,
#     Country == "Egypt" ~ 1, 
#     TRUE~ `Political regime`
#   )) |> dplyr::select(-c(country_name.x, Entity)) -> combined_df
```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}

#removing NA rows, original df should still have all data
 twitter_df %>%
  summarise_all(~ sum(is.na(.)))

twitter_df |> filter(!is.na(log_gdp)) -> twitter_df_fixed
# twitter_df_fixed |> mutate(`Political regime` = `Political regime.x`) |>
#   dplyr::select(-c(`Political regime.y`, `Political regime.x`)) -> twitter_df_fixed
# twitter_df_fixed

twitter_df_fixed %>%
  summarise_all(~ sum(is.na(.)))
  
google_df
google_df |> filter(!is.na(has_google_office)) |> filter(!is.na(log_gdp)) |>
  #mutate(`Political regime` = `Political regime.x`) |>
  #dplyr::select(-c(`Political regime.y`, `Political regime.x`))|> 
  filter(!is.na(`Political regime`)) -> google_df_fixed
  

 
#google_df_fixed



```


```{r, echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
google_df_fixed |> dplyr::mutate(political_regime = `Political regime`) |> 
  dplyr::select(-c(`Political regime`)) -> google_df_fixed

google_df_fixed$political_regime_factor <- as.factor(google_df_fixed$political_regime)

twitter_df_fixed |> dplyr::mutate(political_regime = `Political regime`) |> 
  dplyr::select(-c(`Political regime`)) -> twitter_df_fixed

twitter_df_fixed$political_regime_factor <- as.factor(twitter_df_fixed$political_regime)

```







```{r,echo = FALSE, message = FALSE, results = 'hide', warning = FALSE}
#new conflict modeling starts here

acled_df |> left_join(google_df_fixed, by= c("country_code" = "country_code", "year"="year")) |>
  filter(!is.na(Google.Total.Requests.Percentage)) |> filter(!is.na(Total.Requests))-> google_acled_df_fixed
google_acled_df_fixed
  #filter(!is.na(political_regime_factor))

acled_df |> left_join(twitter_df_fixed, by= c("country_code" = "country_code", "year"="year")) |>
  filter(!is.na(Total.Requests.Percentage)) |> filter(!is.na(Total.requests))-> twitter_acled_df_fixed
  #filter(!is.na(political_regime_factor))



```



```{r}
library(readxl)

getwd()
# Read the Excel file
# Replace 'your_file.xlsx' with your actual file path
# Replace 'Sheet1' with your actual sheet name if needed
raw_data <- read_excel("../data/wgidataset_with_sourcedata.xlsx", sheet = "Sheet1", na = c("", "NA", ".."))

# View the first few rows to confirm
head(raw_data)

# Get a summary to check NA values
summary(raw_data)
```


#import WGI data

```{r}
# dfs = twitter_acled_df_fixed, google_acled_df_fixed, facebook_acled_df
#names(twitter_acled_df_fixed)
head(twitter_acled_df_fixed)


compare_dataframes <- function(df1, df2, df1_name = "df1", df2_name = "df2") {
  # Get column information for both dataframes
  df1_info <- data.frame(
    dataframe = df1_name,
    column = names(df1),
    type = sapply(df1, class),
    stringsAsFactors = FALSE
  )
  
  df2_info <- data.frame(
    dataframe = df2_name,
    column = names(df2),
    type = sapply(df2, class),
    stringsAsFactors = FALSE
  )
  
  # Combine information
  all_info <- rbind(df1_info, df2_info)
  
  # Create comparison table
  comparison <- reshape2::dcast(all_info, column ~ dataframe, value.var = "type")
  
  # Identify differences
  comparison$match <- ifelse(
    is.na(comparison[[df1_name]]) | is.na(comparison[[df2_name]]),
    "Column missing in one dataframe",
    ifelse(comparison[[df1_name]] == comparison[[df2_name]], 
           "Match", 
           "Type mismatch")
  )
   return(comparison)
}
compare_dataframes(twitter_acled_df_fixed,google_acled_df_fixed)

```

```{r}
#date needs to be 2023 - 2015
#convert year into date, will need to apply year data to both beginning and end of year data
names(raw_data)
raw_data |> dplyr::select(c("code", "year", "eiu", "frh", "prs", "ipd")) |>
  dplyr::filter(year >= 2015 & year <= 2023) -> wgi_df



```

```{r}
#join wgi_df to twitter, google and facebook data
names(wgi_df) #code, year
names(twitter_acled_df_fixed) #country_code, year
wgi_df
twitter_acled_df_fixed |> left_join(wgi_df, by = c("country_code" = "code", "year" = "year"))
twitter_acled_df_fixed

```


```{r}




summary(twitter_acled_df_fixed$Date)
summary(google_acled_df_fixed$Date)
summary(facebook_acled_df$Date)

summary(twitter_acled_df_fixed)
google_acled_df_fixed
facebook_acled_df
```

